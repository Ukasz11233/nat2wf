{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37287a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:42:08.727492: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-22 18:42:09.067593: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-22 18:42:09.067642: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-22 18:42:09.069679: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-22 18:42:09.271552: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-22 18:42:09.274021: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 18:42:11.009791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a59315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "\n",
    "file_pattern = f\"data/conve*.txt\"\n",
    "def extract_number(file_name):\n",
    "    match = re.search(r'\\d+', file_name)\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "# Filter files based on the extracted number within the range of 0 to 50\n",
    "filtered_files = [file for file in matching_files if 0 <= extract_number(file) <= 50]\n",
    "matching_files = glob.glob(file_pattern)\n",
    "print(len(filtered_files))\n",
    "print(len(matching_files))\n",
    "input_texts = []\n",
    "output_texts = []\n",
    "df = pd.DataFrame()\n",
    "for file_path in filtered_files:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    examples = content.split(\"assistant: \")\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    i = 1\n",
    "    for example in examples[1:]:\n",
    "        for _ in range(100):\n",
    "            input_match = re.search(f\"Input{i}: (.+?)\\n\", example)\n",
    "            output_match = re.search(f\"Output{i}: (.+?)\\n\", example)\n",
    "\n",
    "            if input_match and output_match:\n",
    "                # outputs_value = \"flowchart TD \\n\\t\" + output_match.group(1)\n",
    "                outputs_value = output_match.group(1)\n",
    "                # outputs_value = format_mermaid_code(outputs_value)\n",
    "                inputs_value = re.sub(r'Output.*', r'', input_match.group(1))\n",
    "                inputs.append(inputs_value)\n",
    "                outputs.append(outputs_value)\n",
    "                output_texts.append(outputs_value)\n",
    "                input_texts.append(inputs_value)\n",
    "            i += 1  \n",
    "    newDf = pd.DataFrame({\"input\": inputs, \"output\": outputs})\n",
    "    df = pd.concat([df, newDf], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4380aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1033\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Define the maximum sequence length for input and output sequences\n",
    "max_input_seq_len = max(len(seq) for seq in input_texts)\n",
    "max_output_seq_len = max(len(seq) for seq in output_texts)\n",
    "\n",
    "# Define the input and output tokenizers\n",
    "input_tokenizer = Tokenizer(filters='', char_level=False)\n",
    "output_tokenizer = Tokenizer(filters='', char_level=False)\n",
    "\n",
    "# Fit the input tokenizer on the preprocessed input sequences\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "print(len(input_tokenizer.word_index))\n",
    "# Fit the output tokenizer on the preprocessed output sequences\n",
    "output_tokenizer.fit_on_texts(output_texts)\n",
    "\n",
    "# Convert the input and output sequences to numerical format\n",
    "encoder_input_seqs = input_tokenizer.texts_to_sequences(input_texts)\n",
    "decoder_input_seqs = output_tokenizer.texts_to_sequences(output_texts)\n",
    "decoder_target_seqs = [seq[1:] for seq in decoder_input_seqs]\n",
    "\n",
    "# Pad the input and output sequences to fixed length\n",
    "encoder_input_seqs = pad_sequences(encoder_input_seqs, maxlen=max_input_seq_len, padding='post')\n",
    "decoder_input_seqs = pad_sequences(decoder_input_seqs, maxlen=max_output_seq_len, padding='post')\n",
    "decoder_target_seqs = pad_sequences(decoder_target_seqs, maxlen=max_output_seq_len, padding='post')\n",
    "\n",
    "# Define the model architecture\n",
    "latent_dim = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_seq_len,))\n",
    "encoder_embedding = Embedding(input_dim=len(input_tokenizer.word_index) + 1, output_dim=latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm, state_h, state_c = LSTM(latent_dim, return_sequences=True, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_seq_len,))\n",
    "decoder_embedding = Embedding(input_dim=len(output_tokenizer.word_index) + 1, output_dim=latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# Attention layer\n",
    "attention = Attention()([decoder_outputs, encoder_lstm])\n",
    "context = Concatenate(axis=-1)([attention, decoder_outputs])\n",
    "\n",
    "# Dense layer for prediction\n",
    "decoder_dense = Dense(len(output_tokenizer.word_index) + 1, activation='softmax')\n",
    "decoder_outputs = decoder_dense(context)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c1e67",
   "metadata": {},
   "source": [
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs, epochs=10, batch_size=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model_latent_dim_64.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc8271ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 22:58:37.464953: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 1800 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Input sentence: Scan a list of prices until finding the one with the highest value\n",
      "Predicted output: ['f[end] up your a b --> a new --> you new list] b --> a b -- no --> b c -- yes --> b c -- yes --> b c -- yes --> b c -- yes --> b']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the trained model\n",
    "model = load_model('my_model_latent_dim_16_retrained3.h5')\n",
    "\n",
    "# Define the input sentence\n",
    "input_sentence = \"Scan a list of prices until finding the one with the highest value\"\n",
    "\n",
    "# Preprocess the input sentence\n",
    "input_sequence = input_tokenizer.texts_to_sequences([input_sentence])\n",
    "padded_input_sequence = pad_sequences(input_sequence, maxlen=max_input_seq_len, padding='post')\n",
    "\n",
    "# Initialize the decoded sequence\n",
    "decoded_sequence = np.zeros((1, max_output_seq_len))\n",
    "\n",
    "# Use the model to predict the output sequence\n",
    "for i in range(max_output_seq_len):\n",
    "    predictions = model.predict([padded_input_sequence, decoded_sequence])\n",
    "    predicted_token_index = np.argmax(predictions[0, i, :])\n",
    "    decoded_sequence[0, i] = predicted_token_index\n",
    "\n",
    "    if predicted_token_index == 0:  # End of sequence token\n",
    "        break\n",
    "\n",
    "# Convert the predicted sequence back to text\n",
    "output_sentence = output_tokenizer.sequences_to_texts([decoded_sequence[0]])\n",
    "\n",
    "print(\"Input sentence:\", input_sentence)\n",
    "print(\"Predicted output:\", output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51c57f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 21:22:27.627862: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 1800 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2293/2293 [==============================] - 581s 252ms/step - loss: 3.4928 - accuracy: 0.4325\n",
      "Epoch 2/10\n",
      "2293/2293 [==============================] - 566s 247ms/step - loss: 3.1967 - accuracy: 0.4574\n",
      "Epoch 3/10\n",
      "2293/2293 [==============================] - 565s 247ms/step - loss: 2.9853 - accuracy: 0.4779\n",
      "Epoch 4/10\n",
      "2293/2293 [==============================] - 567s 247ms/step - loss: 2.8127 - accuracy: 0.4947\n",
      "Epoch 5/10\n",
      "2293/2293 [==============================] - 562s 245ms/step - loss: 2.6676 - accuracy: 0.5065\n",
      "Epoch 6/10\n",
      "2293/2293 [==============================] - 561s 245ms/step - loss: 2.5374 - accuracy: 0.5198\n",
      "Epoch 7/10\n",
      "2293/2293 [==============================] - 559s 244ms/step - loss: 2.4211 - accuracy: 0.5340\n",
      "Epoch 8/10\n",
      "2293/2293 [==============================] - 560s 244ms/step - loss: 2.3187 - accuracy: 0.5451\n",
      "Epoch 9/10\n",
      "2293/2293 [==============================] - 563s 245ms/step - loss: 2.2252 - accuracy: 0.5559\n",
      "Epoch 10/10\n",
      "2293/2293 [==============================] - 562s 245ms/step - loss: 2.1381 - accuracy: 0.5655\n"
     ]
    }
   ],
   "source": [
    "# RETRAINING A NEW MODEL\n",
    "existing_model = load_model('my_model_latent_dim_16.h5')\n",
    "existing_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "existing_model.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs, epochs=10, batch_size=1)\n",
    "existing_model.save('my_model_latent_dim_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81368dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 420)]                0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 653)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 420, 16)              70608     ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 653, 16)              123488    ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, 420, 16),            2112      ['embedding_2[0][0]']         \n",
      "                              (None, 16),                                                         \n",
      "                              (None, 16)]                                                         \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, 653, 16),            2112      ['embedding_3[0][0]',         \n",
      "                              (None, 16),                            'lstm_2[0][1]',              \n",
      "                              (None, 16)]                            'lstm_2[0][2]']              \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 653, 16)              0         ['lstm_3[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 653, 32)              0         ['attention_1[0][0]',         \n",
      " )                                                                   'lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 653, 7718)            254694    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 453014 (1.73 MB)\n",
      "Trainable params: 453014 (1.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('my_model_latent_dim_16.h5')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
