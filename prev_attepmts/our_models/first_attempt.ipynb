{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RLjWzd6FGBUX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:28:05.859490: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 20:28:06.446471: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 20:28:06.449495: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-18 20:28:10.664703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "\n",
    "file_pattern = f\"data/conve*.txt\"\n",
    "matching_files = glob.glob(file_pattern)\n",
    "\n",
    "input_texts = []\n",
    "output_texts = []\n",
    "df = pd.DataFrame()\n",
    "for file_path in matching_files:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    examples = content.split(\"assistant: \")\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    i = 1\n",
    "    for example in examples[1:]:\n",
    "        for _ in range(100):\n",
    "            input_match = re.search(f\"Input{i}: (.+?)\\n\", example)\n",
    "            output_match = re.search(f\"Output{i}: (.+?)\\n\", example)\n",
    "\n",
    "            if input_match and output_match:\n",
    "                # outputs_value = \"flowchart TD \\n\\t\" + output_match.group(1)\n",
    "                outputs_value = output_match.group(1)\n",
    "                # outputs_value = format_mermaid_code(outputs_value)\n",
    "                inputs_value = re.sub(r'Output.*', r'', input_match.group(1))\n",
    "                inputs.append(inputs_value)\n",
    "                outputs.append(outputs_value)\n",
    "                output_texts.append(outputs_value)\n",
    "                input_texts.append(inputs_value)\n",
    "            i += 1  \n",
    "    newDf = pd.DataFrame({\"input\": inputs, \"output\": outputs})\n",
    "    df = pd.concat([df, newDf], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Define the maximum sequence length for input and output sequences\n",
    "max_input_seq_len = max(len(seq) for seq in input_texts)\n",
    "max_output_seq_len = max(len(seq) for seq in output_texts)\n",
    "\n",
    "# Define the input and output tokenizers\n",
    "input_tokenizer = Tokenizer(filters='', char_level=False)\n",
    "output_tokenizer = Tokenizer(filters='', char_level=False)\n",
    "\n",
    "# Fit the input tokenizer on the preprocessed input sequences\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "\n",
    "# Fit the output tokenizer on the preprocessed output sequences\n",
    "output_tokenizer.fit_on_texts(output_texts)\n",
    "\n",
    "# Convert the input and output sequences to numerical format\n",
    "encoder_input_seqs = input_tokenizer.texts_to_sequences(input_texts)\n",
    "decoder_input_seqs = output_tokenizer.texts_to_sequences(output_texts)\n",
    "decoder_target_seqs = [seq[1:] for seq in decoder_input_seqs]\n",
    "\n",
    "# Pad the input and output sequences to fixed length\n",
    "encoder_input_seqs = pad_sequences(encoder_input_seqs, maxlen=max_input_seq_len, padding='post')\n",
    "decoder_input_seqs = pad_sequences(decoder_input_seqs, maxlen=max_output_seq_len, padding='post')\n",
    "decoder_target_seqs = pad_sequences(decoder_target_seqs, maxlen=max_output_seq_len, padding='post')\n",
    "\n",
    "# Define the model architecture\n",
    "latent_dim = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_seq_len,))\n",
    "encoder_embedding = Embedding(input_dim=len(input_tokenizer.word_index) + 1, output_dim=latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm, state_h, state_c = LSTM(latent_dim, return_sequences=True, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_seq_len,))\n",
    "decoder_embedding = Embedding(input_dim=len(output_tokenizer.word_index) + 1, output_dim=latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# Attention layer\n",
    "attention = Attention()([decoder_outputs, encoder_lstm])\n",
    "context = Concatenate(axis=-1)([attention, decoder_outputs])\n",
    "\n",
    "# Dense layer for prediction\n",
    "decoder_dense = Dense(len(output_tokenizer.word_index) + 1, activation='softmax')\n",
    "decoder_outputs = decoder_dense(context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs, epochs=1, batch_size=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the maximum sequence length for the input and output sequences\n",
    "max_input_seq_len = max(len(seq) for seq in input_texts)\n",
    "max_output_seq_len = max(len(seq) for seq in output_texts)\n",
    "\n",
    "# Define the input and output tokenizers\n",
    "input_tokenizer = Tokenizer(filters='', char_level=False)\n",
    "output_tokenizer = Tokenizer(filters='', char_level=False)\n",
    "\n",
    "# Fit the input tokenizer on the preprocessed input sequences\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "\n",
    "# Fit the output tokenizer on the preprocessed output sequences\n",
    "output_tokenizer.fit_on_texts(output_texts)\n",
    "\n",
    "SOS_token = '<sos>'\n",
    "EOS_token = '<eos>'\n",
    "\n",
    "# Add the special tokens to the output tokenizer\n",
    "output_tokenizer.word_index[SOS_token] = len(output_tokenizer.word_index) + 1\n",
    "output_tokenizer.word_index[EOS_token] = len(output_tokenizer.word_index) + 1\n",
    "\n",
    "output_tokenizer.index_word[len(output_tokenizer.index_word) + 1] = SOS_token\n",
    "output_tokenizer.index_word[len(output_tokenizer.index_word) + 1] = EOS_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the number of encoder and decoder tokens\n",
    "num_encoder_tokens = len(input_tokenizer.word_index) + 1\n",
    "num_decoder_tokens = len(output_tokenizer.word_index) + 2\n",
    "\n",
    "# Define the model architecture\n",
    "latent_dim = 256\n",
    "\n",
    "# Define encoder input layer\n",
    "encoder_inputs = Input(shape=(max_input_seq_len,))\n",
    "encoder_embedding = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_dropout = Dropout(0.1)(encoder_embedding)\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True)(encoder_dropout)\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True)(encoder_lstm1)\n",
    "encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_lstm2)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define decoder input layers\n",
    "decoder_inputs = Input(shape=(max_output_seq_len,))\n",
    "decoder_embedding = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_dropout = Dropout(0.1)(decoder_embedding)\n",
    "decoder_lstm1 = LSTM(latent_dim, return_sequences=True)(decoder_dropout, initial_state=encoder_states)\n",
    "decoder_lstm2 = LSTM(latent_dim, return_sequences=True)(decoder_lstm1, initial_state=encoder_states)\n",
    "decoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm3(decoder_lstm2, initial_state=encoder_states)\n",
    "\n",
    "# Define attention layer\n",
    "attention = Attention()([decoder_outputs, encoder_outputs])\n",
    "\n",
    "# Define decoder output layer\n",
    "decoder_dense = Dense(num_decoder_tokens - 1, activation='softmax')\n",
    "decoder_outputs = decoder_dense(attention)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input and output sequences to numerical format\n",
    "encoder_input_seqs = input_tokenizer.texts_to_sequences(input_texts)\n",
    "decoder_input_seqs = [[output_tokenizer.word_index['<sos>']] + output_tokenizer.texts_to_sequences([seq])[0] for seq in output_texts]\n",
    "decoder_target_seqs = [seq[1:] + [output_tokenizer.word_index['<eos>']] for seq in decoder_input_seqs]\n",
    "\n",
    "# Pad the input and output sequences to fixed length\n",
    "encoder_input_seqs = pad_sequences(encoder_input_seqs, maxlen=max_input_seq_len, padding='post')\n",
    "decoder_input_seqs = pad_sequences(decoder_input_seqs, maxlen=max_output_seq_len, padding='post')\n",
    "decoder_target_seqs = pad_sequences(decoder_target_seqs, maxlen=max_output_seq_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:05:48.776339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-11-18 12:06:01.163949: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 1800 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:06:15.505920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:06:26.416952: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:06:37.295515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:06:48.189864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:06:59.160148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:07:10.786159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:07:22.049422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:07:33.533624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:07:45.117631: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:07:56.435118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:08:07.821276: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:08:19.080895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:08:30.488342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:08:42.054991: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:08:53.459748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:09:05.055812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:09:16.492289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:09:27.954062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:09:39.555233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:09:51.405251: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:10:02.828514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:10:14.277982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 23/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:10:25.748525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:10:37.332792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 25/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:10:48.782088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:11:00.080499: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 27/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:11:11.490836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 28/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:11:26.030452: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 29/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:11:43.222954: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:11:57.496836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 31/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:12:10.860506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:12:29.704216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 33/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:12:51.053131: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:13:12.357497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 35/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:13:33.672457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:13:55.014481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 37/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:14:15.911558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:14:37.004203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 39/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:14:58.382253: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:15:19.505070: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 41/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:15:40.093548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 42/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:16:01.087907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 43/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:16:21.752044: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 44/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:16:42.435837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 45/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:17:03.459925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 46/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:17:24.888383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 47/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:17:46.623170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 48/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:18:09.418198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 49/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:18:29.689620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:18:50.433421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 51/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:19:11.562524: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 52/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:19:32.993427: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 53/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:19:55.599574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 54/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:20:17.449260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 55/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:20:39.397868: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 56/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:21:01.145833: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 57/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:21:23.174230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 58/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:21:45.388867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 59/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:22:06.940446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:22:28.327881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 61/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:22:49.258509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 62/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:23:10.130089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 63/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:23:30.798746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:23:52.825351: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 65/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:24:14.561899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 66/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:24:36.587045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 67/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:24:58.462342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 68/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:25:20.406198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 69/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:25:42.790377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 70/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:26:05.329183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 71/72 trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:26:26.184509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [21,653,7720]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-11-18 12:26:40.472259: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 1800 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 72/72 trained\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_batches = int(np.ceil(len(decoder_target_seqs) / batch_size))\n",
    "\n",
    "for batch_num in range(num_batches):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = min((batch_num + 1) * batch_size, len(decoder_target_seqs))\n",
    "\n",
    "    batch_encoder_input_seqs = encoder_input_seqs[start_idx:end_idx]\n",
    "    batch_decoder_input_seqs = decoder_input_seqs[start_idx:end_idx]\n",
    "    batch_decoder_target_seqs = decoder_target_seqs[start_idx:end_idx]\n",
    "    \n",
    "    # Tworzenie macierzy one-hot dla aktualnej porcji danych\n",
    "    current_batch_size = len(batch_decoder_target_seqs)\n",
    "    decoder_target_seqs_onehot = np.zeros((current_batch_size, max_output_seq_len, len(output_tokenizer.word_index) + 1))\n",
    "\n",
    "    for i, seq in enumerate(batch_decoder_target_seqs):\n",
    "        for j, token in enumerate(seq):\n",
    "            decoder_target_seqs_onehot[i, j, token] = 1.0\n",
    "\n",
    "    # Trenowanie modelu na podstawie aktualnej porcji danych\n",
    "    model.train_on_batch([batch_encoder_input_seqs, batch_decoder_input_seqs], decoder_target_seqs_onehot)\n",
    "    print(f'Batch {batch_num+1}/{num_batches} trained')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to jest niepotrzebne\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs_onehot,\n",
    "          batch_size=64,\n",
    "          epochs=800,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to jest niepotrzebne\n",
    "\n",
    "model.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs_onehot,\n",
    "          batch_size=64,\n",
    "          epochs=400,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1, 3\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Use beam search for decoding\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_output_seq_len):\n\u001b[0;32m---> 17\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpadded_input_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoded_sequences\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Select top-k indices using beam search\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     top_k_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(predictions[\u001b[38;5;241m0\u001b[39m, i, :])[\u001b[38;5;241m-\u001b[39mbeam_width:][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_lab/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_lab/lib/python3.10/site-packages/keras/engine/data_adapter.py:1852\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1846\u001b[0m         label,\n\u001b[1;32m   1847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1848\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1849\u001b[0m         ),\n\u001b[1;32m   1850\u001b[0m     )\n\u001b[1;32m   1851\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1852\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1, 3\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = load_model('my_model2.h5')\n",
    "\n",
    "# Define the input sentence\n",
    "input_sentence = \"To make a cup of tea, start by grinding the beans. Afterwards, add the grounds to the tea maker and add water. Finally, press the brew button and enjoy your tea\"\n",
    "\n",
    "# Preprocess the input sentence\n",
    "input_sequence = input_tokenizer.texts_to_sequences([input_sentence])\n",
    "padded_input_sequence = pad_sequences(input_sequence, maxlen=max_input_seq_len, padding='post')\n",
    "\n",
    "# Initialize the decoded sequence with beam search\n",
    "beam_width = 3\n",
    "decoded_sequences = np.zeros((beam_width, max_output_seq_len))\n",
    "\n",
    "# Use beam search for decoding\n",
    "for i in range(max_output_seq_len):\n",
    "    predictions = model.predict([padded_input_sequence, decoded_sequences])\n",
    "    \n",
    "    # Select top-k indices using beam search\n",
    "    top_k_indices = np.argsort(predictions[0, i, :])[-beam_width:][::-1]\n",
    "\n",
    "    # Expand the beam\n",
    "    new_sequences = decoded_sequences.copy()\n",
    "    for j, idx in enumerate(top_k_indices):\n",
    "        new_sequences[j, i] = idx\n",
    "\n",
    "    decoded_sequences = new_sequences\n",
    "\n",
    "# Convert the predicted sequences back to text\n",
    "output_sentences = [output_tokenizer.sequences_to_texts([decoded_sequence]) for decoded_sequence in decoded_sequences]\n",
    "\n",
    "print(\"Input sentence:\", input_sentence)\n",
    "print(\"Predicted outputs:\")\n",
    "for output_sentence in output_sentences:\n",
    "    print(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<sos>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Generate the output sequence using the trained model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_seq), max_output_seq_len))\n\u001b[0;32m---> 10\u001b[0m decoder_input[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43moutput_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<sos>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_output_seq_len):\n\u001b[1;32m     12\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([input_seq, decoder_input])\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '<sos>'"
     ]
    }
   ],
   "source": [
    "input_text = \"To make a cup of tea, start by grinding the beans. Afterwards, add the grounds to the tea maker and add water. Finally, press the brew button and enjoy your tea\"\n",
    "\n",
    "# Tokenize the input sentence\n",
    "input_seq = input_tokenizer.texts_to_sequences([input_text])[0]\n",
    "# Pad the input sequence\n",
    "input_seq = pad_sequences([input_seq], maxlen=max_input_seq_len, padding='post')\n",
    "\n",
    "# Generate the output sequence using the trained model\n",
    "decoder_input = np.zeros(shape=(len(input_seq), max_output_seq_len))\n",
    "decoder_input[:, 0] = output_tokenizer.word_index['<sos>']\n",
    "for i in range(1, max_output_seq_len):\n",
    "    predictions = model.predict([input_seq, decoder_input]).argmax(axis=2)\n",
    "    decoder_input[:, i] = predictions[:, i-1]\n",
    "\n",
    "print(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the output sequence to text\n",
    "output_text = ''\n",
    "for i in range(max_output_seq_len):\n",
    "    # print(int(decoder_input[0,i]))\n",
    "    # print(output_tokenizer.index_word)\n",
    "    if output_tokenizer.index_word[int(decoder_input[0,i])] == '<sos>':\n",
    "        continue\n",
    "    if output_tokenizer.index_word[int(decoder_input[0,i])] == '<eos>':\n",
    "        break\n",
    "    else:\n",
    "        output_text += output_tokenizer.index_word[int(decoder_input[0,i])] + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: To make a cup of tea, start by grinding the beans. Afterwards, add the grounds to the tea maker and add water. Finally, press the brew button and enjoy your tea\n",
      "Output sentence: --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> --> \n"
     ]
    }
   ],
   "source": [
    "# Print the input and output sentences\n",
    "print('Input sentence:', input_text)\n",
    "print('Output sentence:', output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the input and output sentences\n",
    "print('Input sentence:', input_text)\n",
    "print('Output sentence:', output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the input and output sentences\n",
    "print('Input sentence:', input_text)\n",
    "print('Output sentence:', output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10137.     0.     0. ...     0.     0.     0.]\n",
      " [10137.     0.     0. ...     0.     0.     0.]]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Test example 1 predicted text: --> e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take\n",
      "Test example 2 predicted text: --> e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take e[take\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the test examples\n",
    "test_encoder_input_seqs = input_tokenizer.texts_to_sequences(input_texts[4:6])\n",
    "test_encoder_input_seqs = pad_sequences(test_encoder_input_seqs, maxlen=max_input_seq_len, padding='post')\n",
    "\n",
    "# Initialize the decoder input sequences with the SOS token\n",
    "test_decoder_input_seqs = np.zeros((len(test_encoder_input_seqs), max_output_seq_len))\n",
    "test_decoder_input_seqs[:, 0] = output_tokenizer.word_index[SOS_token]\n",
    "print(test_decoder_input_seqs)\n",
    "\n",
    "# Generate predictions on the test examples\n",
    "predictions = model.predict([test_encoder_input_seqs, test_decoder_input_seqs])\n",
    "\n",
    "# Convert the predictions to text format\n",
    "predicted_texts = []\n",
    "for prediction in predictions:\n",
    "    predicted_seq = []\n",
    "    for token_vec in prediction:\n",
    "        token_index = np.argmax(token_vec)\n",
    "        token = output_tokenizer.index_word[token_index]\n",
    "        if token == EOS_token:\n",
    "            break\n",
    "        predicted_seq.append(token)\n",
    "    predicted_texts.append(' '.join(predicted_seq))\n",
    "\n",
    "# Print the predicted texts\n",
    "for i, predicted_text in enumerate(predicted_texts):\n",
    "    print(\"Test example\", i+1, \"predicted text:\", predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
